{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Copy of Classification_MNIST_DNN_TensorFlow.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhavadama/tensorflow/blob/master/Classification_MNIST_DNN_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dzdup9KW8yU",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Classification with DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBxGFgCPW8yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euSSgznuW8yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reset tensorflow graph\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grQQ6bERW8yu",
        "colab_type": "text"
      },
      "source": [
        "Step 1 : Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgZl0Q0GW8yv",
        "colab_type": "code",
        "outputId": "17c90421-a78a-41f8-bcae-adc9b5cfc01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnists = input_data.read_data_sets('MNIST_data')\n",
        "trai = mnists.train.images\n",
        "trt = mnists.train.labels\n",
        "trt[0:1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-cea1a206c578>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmo5OKEcW8y1",
        "colab_type": "code",
        "outputId": "32e65361-db73-41e2-d65c-80db2a2c16d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKFJeMxHW8y7",
        "colab_type": "code",
        "outputId": "7d4489d7-69af-472c-bc6e-36e11218d9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd1a8012c18>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd191d02ac8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd191d02be0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUuvfLfwW8zA",
        "colab_type": "text"
      },
      "source": [
        "Step 1a : Get Training and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGMiIygDW8zB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = mnist.train.images\n",
        "trainY = mnist.train.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSgGLXhjW8zH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testX = mnist.test.images\n",
        "testY = mnist.test.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttHVMQMfW8zK",
        "colab_type": "text"
      },
      "source": [
        "How many Training and Test Examples?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAEsO2V289E5",
        "colab_type": "code",
        "outputId": "c68693c2-0589-442f-92fc-539948813da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe_4TBXbW8zK",
        "colab_type": "code",
        "outputId": "f95976ec-f25e-4236-852b-327755e1ad20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainY[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrTeJLiTW8zN",
        "colab_type": "text"
      },
      "source": [
        "Lets define some parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKUS2An99m5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir mytflogs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeExHZ_qW8zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# /content/\n",
        "logs_path = \"/content/mytflogs/\"\n",
        "learning_rate = 0.04\n",
        "n_features = trainX.shape[1]\n",
        "n_classes = trainY.shape[1]\n",
        "model_name = 'mnist.ckpt'\n",
        "\n",
        "#How many examples to feed for training at one time\n",
        "batch_size = 100\n",
        "\n",
        "#How many times all the data to be shown\n",
        "training_epochs = 100\n",
        "\n",
        "K = 200  \n",
        "L = 100  # 150 \n",
        "M = 60   # 100\n",
        "N = 30  # 50 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZI-QBQc-X4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for each_Epoch in totalEPoch:\n",
        "  for each_batch_of_data in total_Batch:\n",
        "    # do the optimization / learning \n",
        "    # calculate the weight and loss \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuhlSnbrW8zP",
        "colab_type": "text"
      },
      "source": [
        "# Build the Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk1McFvRW8zP",
        "colab_type": "text"
      },
      "source": [
        "Input placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfot--syW8zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('input'):\n",
        "    # None -> batch size can be any size, with n_features\n",
        "    x = tf.placeholder(tf.float32, shape=[None, n_features], name=\"x-input\") \n",
        "    # target n_classes output classes\n",
        "    y_ = tf.placeholder(tf.float32, shape=[None, n_classes], name=\"y-input\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pphsG8dW8zS",
        "colab_type": "text"
      },
      "source": [
        "Layer 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYMU9oUz_tHc",
        "colab_type": "text"
      },
      "source": [
        "THis is Hidden Layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4akm7ymBReT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K = 200  \n",
        "L = 100  # 150 \n",
        "M = 60   # 100\n",
        "N = 30  # 50 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XvVLveXCxXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensorflow -- though it's python based; but uses the concept like c/java to initialize the data structure first \n",
        "# Keras - it's python and does initialise the data structure dynamically \n",
        "# pytorch - same as keras "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxo0ZOXZA2qX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "784 (Input)  --> 200 ---> 100 --> 60 --> 30 ---> 10  (Output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybAq1wBLW8zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('layer_1'):\n",
        "    W1 = tf.Variable(tf.truncated_normal([n_features, K], stddev=0.1))\n",
        "    b1 = tf.Variable(tf.zeros([K]))\n",
        "    Y1 = tf.nn.sigmoid(tf.add(tf.matmul(x,W1),b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRm3IUxsW8zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('layer_2'):\n",
        "    W2 = tf.Variable(tf.truncated_normal([K, L], stddev=0.1))\n",
        "    b2 = tf.Variable(tf.zeros([L]))\n",
        "    Y2 = tf.nn.sigmoid(tf.add(tf.matmul(Y1,W2),b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1XBCNtDW8zV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('layer_3'):\n",
        "    W3 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
        "    b3 = tf.Variable(tf.zeros([M]))\n",
        "    Y3 = tf.nn.sigmoid(tf.add(tf.matmul(Y2,W3),b3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRyUtzoeW8zX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('layer_4'):\n",
        "    W4 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n",
        "    b4 = tf.Variable(tf.zeros([N]))\n",
        "    Y4 = tf.nn.sigmoid(tf.add(tf.matmul(Y3,W4),b4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "qKU-g2ZsW8zY",
        "colab_type": "text"
      },
      "source": [
        "Prediction    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePaNRB8b_wMm",
        "colab_type": "text"
      },
      "source": [
        "This is putput layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2bgqjGnW8zZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"Output\"):\n",
        "    W5 = tf.Variable(tf.truncated_normal([N,n_classes], stddev=0.1))\n",
        "    b5 = tf.Variable(tf.zeros([n_classes]))\n",
        "    y = tf.nn.softmax(tf.matmul(Y4,W5) + b5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrC1Sji6W8zb",
        "colab_type": "text"
      },
      "source": [
        "Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS_sLGjCW8zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reduce_sum --> Sigma from the equation \n",
        "with tf.name_scope('Loss'):\n",
        "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-VHGMP-W8zg",
        "colab_type": "text"
      },
      "source": [
        "GradientDescent Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhmJp1pOW8zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('train_opt'):        \n",
        "    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSPgaEQWW8zj",
        "colab_type": "text"
      },
      "source": [
        "Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB2HveEKW8zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('Accuracy'):\n",
        "    prediction = tf.argmax(y,1,name=\"Predict\")    \n",
        "    correct_prediction = tf.equal(prediction, tf.argmax(y_,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ0XiSlbW8zl",
        "colab_type": "text"
      },
      "source": [
        "Loss and Accuracy Logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnpH-VvcW8zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a summary for our cost and accuracy\n",
        "training_loss = tf.summary.scalar(\"training_loss\", cross_entropy)\n",
        "training_accuracy = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
        "test_loss = tf.summary.scalar(\"test_loss\", cross_entropy)\n",
        "test_accuracy = tf.summary.scalar(\"test_accuracy\", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9xy8RhGW8zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a Saver to save the graph\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkX4quhIW8zs",
        "colab_type": "text"
      },
      "source": [
        "# Execute the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFXMDoRZW8zv",
        "colab_type": "code",
        "outputId": "02213830-4212-4d63-e6a4-1528904e2b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "#Start Graph execution\n",
        "with tf.Session() as sess:\n",
        "    # variables need to be initialized before we can use them\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # create log writer object\n",
        "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
        "\n",
        "    # perform training cycles\n",
        "    for epoch in range(training_epochs):\n",
        "        \n",
        "        # number of batches in one epoch\n",
        "        batch_count = int(trainX.shape[0]/batch_size)\n",
        "        \n",
        "        for i in range(batch_count):\n",
        "            batch_x  = trainX[i*batch_size:i*batch_size+batch_size]\n",
        "            batch_y  = trainY[i*batch_size:i*batch_size+batch_size]\n",
        "\n",
        "            # perform the operations we defined earlier on batch\n",
        "            _,acc,loss = sess.run([train_op, training_accuracy,training_loss], \n",
        "                                  feed_dict={x: batch_x, y_: batch_y})\n",
        "            \n",
        "            #log training accuracy and loss\n",
        "            writer.add_summary(acc, epoch * batch_count + i)\n",
        "            writer.add_summary(loss, epoch * batch_count + i)    \n",
        "                       \n",
        "        #Test loss and accuracy\n",
        "        #pls note we are giving test data\n",
        "        acc,loss = sess.run([test_accuracy,test_loss],\n",
        "                                   feed_dict={x: testX, y_: testY})\n",
        "        writer.add_summary(acc, epoch * batch_count + i)\n",
        "        writer.add_summary(loss, epoch * batch_count + i)\n",
        "        \n",
        "        if epoch % 5 == 0: \n",
        "            print (\"Epoch: \", epoch)\n",
        "            print (\"Test Accuracy: \", accuracy.eval(feed_dict={x: testX, y_: testY}))               \n",
        "    \n",
        "    \n",
        "    #Save the model\n",
        "    saver.save(sess, logs_path + '/' + model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Test Accuracy:  0.1028\n",
            "Epoch:  5\n",
            "Test Accuracy:  0.1028\n",
            "Epoch:  10\n",
            "Test Accuracy:  0.1028\n",
            "Epoch:  15\n",
            "Test Accuracy:  0.1168\n",
            "Epoch:  20\n",
            "Test Accuracy:  0.345\n",
            "Epoch:  25\n",
            "Test Accuracy:  0.5401\n",
            "Epoch:  30\n",
            "Test Accuracy:  0.7319\n",
            "Epoch:  35\n",
            "Test Accuracy:  0.8306\n",
            "Epoch:  40\n",
            "Test Accuracy:  0.8827\n",
            "Epoch:  45\n",
            "Test Accuracy:  0.9026\n",
            "Epoch:  50\n",
            "Test Accuracy:  0.9143\n",
            "Epoch:  55\n",
            "Test Accuracy:  0.9242\n",
            "Epoch:  60\n",
            "Test Accuracy:  0.9298\n",
            "Epoch:  65\n",
            "Test Accuracy:  0.9361\n",
            "Epoch:  70\n",
            "Test Accuracy:  0.9396\n",
            "Epoch:  75\n",
            "Test Accuracy:  0.9431\n",
            "Epoch:  80\n",
            "Test Accuracy:  0.9465\n",
            "Epoch:  85\n",
            "Test Accuracy:  0.9502\n",
            "Epoch:  90\n",
            "Test Accuracy:  0.9541\n",
            "Epoch:  95\n",
            "Test Accuracy:  0.9556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S8TsUiXW8zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}