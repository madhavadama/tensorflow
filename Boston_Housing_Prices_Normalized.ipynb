{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of Boston_Housing_Prices_Normalized.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhavadama/tensorflow/blob/master/Boston_Housing_Prices_Normalized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idLG9puGhOhc",
        "colab_type": "text"
      },
      "source": [
        "# Building a Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2k2oZJq6blt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK2CIQ_mhOhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9ptwssGhOhw",
        "colab_type": "text"
      },
      "source": [
        "Reset Default graph - Needed only for Jupyter notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmk6cNI-hOh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3-GxNaohOh_",
        "colab_type": "text"
      },
      "source": [
        "# Step 1 - Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k62nQK_mhOiB",
        "colab_type": "code",
        "outputId": "fad27d75-7808-4f1d-bf8f-cd0a63292cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#Good people at tensorflow have provided the data \n",
        "from tensorflow.contrib.learn import datasets\n",
        "\n",
        "boston = datasets.load_dataset('boston')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-938abce5ef04>:3: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_boston (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use scikits.learn.datasets.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:129: load_csv_with_header (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.data instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRoEgOx5hOiE",
        "colab_type": "code",
        "outputId": "125e330c-23ca-498b-dd26-de55d4c83c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "boston.data[1:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
              "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
              "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
              "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
              "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
              "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
              "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9690e+02, 5.3300e+00],\n",
              "       [2.9850e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        6.4300e+00, 5.8700e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9412e+02, 5.2100e+00],\n",
              "       [8.8290e-02, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01,\n",
              "        6.0120e+00, 6.6600e+01, 5.5605e+00, 5.0000e+00, 3.1100e+02,\n",
              "        1.5200e+01, 3.9560e+02, 1.2430e+01],\n",
              "       [1.4455e-01, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01,\n",
              "        6.1720e+00, 9.6100e+01, 5.9505e+00, 5.0000e+00, 3.1100e+02,\n",
              "        1.5200e+01, 3.9690e+02, 1.9150e+01],\n",
              "       [2.1124e-01, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01,\n",
              "        5.6310e+00, 1.0000e+02, 6.0821e+00, 5.0000e+00, 3.1100e+02,\n",
              "        1.5200e+01, 3.8663e+02, 2.9930e+01],\n",
              "       [1.7004e-01, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01,\n",
              "        6.0040e+00, 8.5900e+01, 6.5921e+00, 5.0000e+00, 3.1100e+02,\n",
              "        1.5200e+01, 3.8671e+02, 1.7100e+01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOMJpyVm_ibG",
        "colab_type": "code",
        "outputId": "a20684ce-546c-4f8c-fb8c-8ed148fcbe79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "boston.target"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSyXZoka_Vga",
        "colab_type": "code",
        "outputId": "801253f4-3ab5-4d06-f09a-eaac1adc54ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "boston.target.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT4loXnFhOiJ",
        "colab_type": "text"
      },
      "source": [
        "#Step 1a - Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou3nz2sshOiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input features\n",
        "features = np.array(boston.data)\n",
        "\n",
        "#Actual output\n",
        "prices = np.array(boston.target)\n",
        "prices = np.reshape(prices,[-1,1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw5cHoD9hOiQ",
        "colab_type": "code",
        "outputId": "93bfcd99-91c6-4d19-deba-ba0bc0014f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "        4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "        9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "        4.0300e+00],\n",
              "       ...,\n",
              "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        5.6400e+00],\n",
              "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "        6.4800e+00],\n",
              "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        7.8800e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AA8rl3u_vsE",
        "colab_type": "code",
        "outputId": "7b3387b7-b95d-4fb2-80d2-57886ef7bc8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "prices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[24. ],\n",
              "       [21.6],\n",
              "       [34.7],\n",
              "       [33.4],\n",
              "       [36.2],\n",
              "       [28.7],\n",
              "       [22.9],\n",
              "       [27.1],\n",
              "       [16.5],\n",
              "       [18.9],\n",
              "       [15. ],\n",
              "       [18.9],\n",
              "       [21.7],\n",
              "       [20.4],\n",
              "       [18.2],\n",
              "       [19.9],\n",
              "       [23.1],\n",
              "       [17.5],\n",
              "       [20.2],\n",
              "       [18.2],\n",
              "       [13.6],\n",
              "       [19.6],\n",
              "       [15.2],\n",
              "       [14.5],\n",
              "       [15.6],\n",
              "       [13.9],\n",
              "       [16.6],\n",
              "       [14.8],\n",
              "       [18.4],\n",
              "       [21. ],\n",
              "       [12.7],\n",
              "       [14.5],\n",
              "       [13.2],\n",
              "       [13.1],\n",
              "       [13.5],\n",
              "       [18.9],\n",
              "       [20. ],\n",
              "       [21. ],\n",
              "       [24.7],\n",
              "       [30.8],\n",
              "       [34.9],\n",
              "       [26.6],\n",
              "       [25.3],\n",
              "       [24.7],\n",
              "       [21.2],\n",
              "       [19.3],\n",
              "       [20. ],\n",
              "       [16.6],\n",
              "       [14.4],\n",
              "       [19.4],\n",
              "       [19.7],\n",
              "       [20.5],\n",
              "       [25. ],\n",
              "       [23.4],\n",
              "       [18.9],\n",
              "       [35.4],\n",
              "       [24.7],\n",
              "       [31.6],\n",
              "       [23.3],\n",
              "       [19.6],\n",
              "       [18.7],\n",
              "       [16. ],\n",
              "       [22.2],\n",
              "       [25. ],\n",
              "       [33. ],\n",
              "       [23.5],\n",
              "       [19.4],\n",
              "       [22. ],\n",
              "       [17.4],\n",
              "       [20.9],\n",
              "       [24.2],\n",
              "       [21.7],\n",
              "       [22.8],\n",
              "       [23.4],\n",
              "       [24.1],\n",
              "       [21.4],\n",
              "       [20. ],\n",
              "       [20.8],\n",
              "       [21.2],\n",
              "       [20.3],\n",
              "       [28. ],\n",
              "       [23.9],\n",
              "       [24.8],\n",
              "       [22.9],\n",
              "       [23.9],\n",
              "       [26.6],\n",
              "       [22.5],\n",
              "       [22.2],\n",
              "       [23.6],\n",
              "       [28.7],\n",
              "       [22.6],\n",
              "       [22. ],\n",
              "       [22.9],\n",
              "       [25. ],\n",
              "       [20.6],\n",
              "       [28.4],\n",
              "       [21.4],\n",
              "       [38.7],\n",
              "       [43.8],\n",
              "       [33.2],\n",
              "       [27.5],\n",
              "       [26.5],\n",
              "       [18.6],\n",
              "       [19.3],\n",
              "       [20.1],\n",
              "       [19.5],\n",
              "       [19.5],\n",
              "       [20.4],\n",
              "       [19.8],\n",
              "       [19.4],\n",
              "       [21.7],\n",
              "       [22.8],\n",
              "       [18.8],\n",
              "       [18.7],\n",
              "       [18.5],\n",
              "       [18.3],\n",
              "       [21.2],\n",
              "       [19.2],\n",
              "       [20.4],\n",
              "       [19.3],\n",
              "       [22. ],\n",
              "       [20.3],\n",
              "       [20.5],\n",
              "       [17.3],\n",
              "       [18.8],\n",
              "       [21.4],\n",
              "       [15.7],\n",
              "       [16.2],\n",
              "       [18. ],\n",
              "       [14.3],\n",
              "       [19.2],\n",
              "       [19.6],\n",
              "       [23. ],\n",
              "       [18.4],\n",
              "       [15.6],\n",
              "       [18.1],\n",
              "       [17.4],\n",
              "       [17.1],\n",
              "       [13.3],\n",
              "       [17.8],\n",
              "       [14. ],\n",
              "       [14.4],\n",
              "       [13.4],\n",
              "       [15.6],\n",
              "       [11.8],\n",
              "       [13.8],\n",
              "       [15.6],\n",
              "       [14.6],\n",
              "       [17.8],\n",
              "       [15.4],\n",
              "       [21.5],\n",
              "       [19.6],\n",
              "       [15.3],\n",
              "       [19.4],\n",
              "       [17. ],\n",
              "       [15.6],\n",
              "       [13.1],\n",
              "       [41.3],\n",
              "       [24.3],\n",
              "       [23.3],\n",
              "       [27. ],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [22.7],\n",
              "       [25. ],\n",
              "       [50. ],\n",
              "       [23.8],\n",
              "       [23.8],\n",
              "       [22.3],\n",
              "       [17.4],\n",
              "       [19.1],\n",
              "       [23.1],\n",
              "       [23.6],\n",
              "       [22.6],\n",
              "       [29.4],\n",
              "       [23.2],\n",
              "       [24.6],\n",
              "       [29.9],\n",
              "       [37.2],\n",
              "       [39.8],\n",
              "       [36.2],\n",
              "       [37.9],\n",
              "       [32.5],\n",
              "       [26.4],\n",
              "       [29.6],\n",
              "       [50. ],\n",
              "       [32. ],\n",
              "       [29.8],\n",
              "       [34.9],\n",
              "       [37. ],\n",
              "       [30.5],\n",
              "       [36.4],\n",
              "       [31.1],\n",
              "       [29.1],\n",
              "       [50. ],\n",
              "       [33.3],\n",
              "       [30.3],\n",
              "       [34.6],\n",
              "       [34.9],\n",
              "       [32.9],\n",
              "       [24.1],\n",
              "       [42.3],\n",
              "       [48.5],\n",
              "       [50. ],\n",
              "       [22.6],\n",
              "       [24.4],\n",
              "       [22.5],\n",
              "       [24.4],\n",
              "       [20. ],\n",
              "       [21.7],\n",
              "       [19.3],\n",
              "       [22.4],\n",
              "       [28.1],\n",
              "       [23.7],\n",
              "       [25. ],\n",
              "       [23.3],\n",
              "       [28.7],\n",
              "       [21.5],\n",
              "       [23. ],\n",
              "       [26.7],\n",
              "       [21.7],\n",
              "       [27.5],\n",
              "       [30.1],\n",
              "       [44.8],\n",
              "       [50. ],\n",
              "       [37.6],\n",
              "       [31.6],\n",
              "       [46.7],\n",
              "       [31.5],\n",
              "       [24.3],\n",
              "       [31.7],\n",
              "       [41.7],\n",
              "       [48.3],\n",
              "       [29. ],\n",
              "       [24. ],\n",
              "       [25.1],\n",
              "       [31.5],\n",
              "       [23.7],\n",
              "       [23.3],\n",
              "       [22. ],\n",
              "       [20.1],\n",
              "       [22.2],\n",
              "       [23.7],\n",
              "       [17.6],\n",
              "       [18.5],\n",
              "       [24.3],\n",
              "       [20.5],\n",
              "       [24.5],\n",
              "       [26.2],\n",
              "       [24.4],\n",
              "       [24.8],\n",
              "       [29.6],\n",
              "       [42.8],\n",
              "       [21.9],\n",
              "       [20.9],\n",
              "       [44. ],\n",
              "       [50. ],\n",
              "       [36. ],\n",
              "       [30.1],\n",
              "       [33.8],\n",
              "       [43.1],\n",
              "       [48.8],\n",
              "       [31. ],\n",
              "       [36.5],\n",
              "       [22.8],\n",
              "       [30.7],\n",
              "       [50. ],\n",
              "       [43.5],\n",
              "       [20.7],\n",
              "       [21.1],\n",
              "       [25.2],\n",
              "       [24.4],\n",
              "       [35.2],\n",
              "       [32.4],\n",
              "       [32. ],\n",
              "       [33.2],\n",
              "       [33.1],\n",
              "       [29.1],\n",
              "       [35.1],\n",
              "       [45.4],\n",
              "       [35.4],\n",
              "       [46. ],\n",
              "       [50. ],\n",
              "       [32.2],\n",
              "       [22. ],\n",
              "       [20.1],\n",
              "       [23.2],\n",
              "       [22.3],\n",
              "       [24.8],\n",
              "       [28.5],\n",
              "       [37.3],\n",
              "       [27.9],\n",
              "       [23.9],\n",
              "       [21.7],\n",
              "       [28.6],\n",
              "       [27.1],\n",
              "       [20.3],\n",
              "       [22.5],\n",
              "       [29. ],\n",
              "       [24.8],\n",
              "       [22. ],\n",
              "       [26.4],\n",
              "       [33.1],\n",
              "       [36.1],\n",
              "       [28.4],\n",
              "       [33.4],\n",
              "       [28.2],\n",
              "       [22.8],\n",
              "       [20.3],\n",
              "       [16.1],\n",
              "       [22.1],\n",
              "       [19.4],\n",
              "       [21.6],\n",
              "       [23.8],\n",
              "       [16.2],\n",
              "       [17.8],\n",
              "       [19.8],\n",
              "       [23.1],\n",
              "       [21. ],\n",
              "       [23.8],\n",
              "       [23.1],\n",
              "       [20.4],\n",
              "       [18.5],\n",
              "       [25. ],\n",
              "       [24.6],\n",
              "       [23. ],\n",
              "       [22.2],\n",
              "       [19.3],\n",
              "       [22.6],\n",
              "       [19.8],\n",
              "       [17.1],\n",
              "       [19.4],\n",
              "       [22.2],\n",
              "       [20.7],\n",
              "       [21.1],\n",
              "       [19.5],\n",
              "       [18.5],\n",
              "       [20.6],\n",
              "       [19. ],\n",
              "       [18.7],\n",
              "       [32.7],\n",
              "       [16.5],\n",
              "       [23.9],\n",
              "       [31.2],\n",
              "       [17.5],\n",
              "       [17.2],\n",
              "       [23.1],\n",
              "       [24.5],\n",
              "       [26.6],\n",
              "       [22.9],\n",
              "       [24.1],\n",
              "       [18.6],\n",
              "       [30.1],\n",
              "       [18.2],\n",
              "       [20.6],\n",
              "       [17.8],\n",
              "       [21.7],\n",
              "       [22.7],\n",
              "       [22.6],\n",
              "       [25. ],\n",
              "       [19.9],\n",
              "       [20.8],\n",
              "       [16.8],\n",
              "       [21.9],\n",
              "       [27.5],\n",
              "       [21.9],\n",
              "       [23.1],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [13.8],\n",
              "       [13.8],\n",
              "       [15. ],\n",
              "       [13.9],\n",
              "       [13.3],\n",
              "       [13.1],\n",
              "       [10.2],\n",
              "       [10.4],\n",
              "       [10.9],\n",
              "       [11.3],\n",
              "       [12.3],\n",
              "       [ 8.8],\n",
              "       [ 7.2],\n",
              "       [10.5],\n",
              "       [ 7.4],\n",
              "       [10.2],\n",
              "       [11.5],\n",
              "       [15.1],\n",
              "       [23.2],\n",
              "       [ 9.7],\n",
              "       [13.8],\n",
              "       [12.7],\n",
              "       [13.1],\n",
              "       [12.5],\n",
              "       [ 8.5],\n",
              "       [ 5. ],\n",
              "       [ 6.3],\n",
              "       [ 5.6],\n",
              "       [ 7.2],\n",
              "       [12.1],\n",
              "       [ 8.3],\n",
              "       [ 8.5],\n",
              "       [ 5. ],\n",
              "       [11.9],\n",
              "       [27.9],\n",
              "       [17.2],\n",
              "       [27.5],\n",
              "       [15. ],\n",
              "       [17.2],\n",
              "       [17.9],\n",
              "       [16.3],\n",
              "       [ 7. ],\n",
              "       [ 7.2],\n",
              "       [ 7.5],\n",
              "       [10.4],\n",
              "       [ 8.8],\n",
              "       [ 8.4],\n",
              "       [16.7],\n",
              "       [14.2],\n",
              "       [20.8],\n",
              "       [13.4],\n",
              "       [11.7],\n",
              "       [ 8.3],\n",
              "       [10.2],\n",
              "       [10.9],\n",
              "       [11. ],\n",
              "       [ 9.5],\n",
              "       [14.5],\n",
              "       [14.1],\n",
              "       [16.1],\n",
              "       [14.3],\n",
              "       [11.7],\n",
              "       [13.4],\n",
              "       [ 9.6],\n",
              "       [ 8.7],\n",
              "       [ 8.4],\n",
              "       [12.8],\n",
              "       [10.5],\n",
              "       [17.1],\n",
              "       [18.4],\n",
              "       [15.4],\n",
              "       [10.8],\n",
              "       [11.8],\n",
              "       [14.9],\n",
              "       [12.6],\n",
              "       [14.1],\n",
              "       [13. ],\n",
              "       [13.4],\n",
              "       [15.2],\n",
              "       [16.1],\n",
              "       [17.8],\n",
              "       [14.9],\n",
              "       [14.1],\n",
              "       [12.7],\n",
              "       [13.5],\n",
              "       [14.9],\n",
              "       [20. ],\n",
              "       [16.4],\n",
              "       [17.7],\n",
              "       [19.5],\n",
              "       [20.2],\n",
              "       [21.4],\n",
              "       [19.9],\n",
              "       [19. ],\n",
              "       [19.1],\n",
              "       [19.1],\n",
              "       [20.1],\n",
              "       [19.9],\n",
              "       [19.6],\n",
              "       [23.2],\n",
              "       [29.8],\n",
              "       [13.8],\n",
              "       [13.3],\n",
              "       [16.7],\n",
              "       [12. ],\n",
              "       [14.6],\n",
              "       [21.4],\n",
              "       [23. ],\n",
              "       [23.7],\n",
              "       [25. ],\n",
              "       [21.8],\n",
              "       [20.6],\n",
              "       [21.2],\n",
              "       [19.1],\n",
              "       [20.6],\n",
              "       [15.2],\n",
              "       [ 7. ],\n",
              "       [ 8.1],\n",
              "       [13.6],\n",
              "       [20.1],\n",
              "       [21.8],\n",
              "       [24.5],\n",
              "       [23.1],\n",
              "       [19.7],\n",
              "       [18.3],\n",
              "       [21.2],\n",
              "       [17.5],\n",
              "       [16.8],\n",
              "       [22.4],\n",
              "       [20.6],\n",
              "       [23.9],\n",
              "       [22. ],\n",
              "       [11.9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP5HCkSshOiT",
        "colab_type": "code",
        "outputId": "0fc3eee6-a6e6-4427-833e-bdfd9be9e59e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prices.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UIx_0tGhOiV",
        "colab_type": "text"
      },
      "source": [
        "How many examples do we have?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5x1LEjChOiW",
        "colab_type": "text"
      },
      "source": [
        "# Building the graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf4pxTu0hOiX",
        "colab_type": "text"
      },
      "source": [
        "Define input data placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvle5VWjhOiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input features\n",
        "x = tf.placeholder(shape=[None,13],dtype=tf.float32, name='x-input')\n",
        "\n",
        "#Actual Output\n",
        "# Actual Y Value \n",
        "y_ = tf.placeholder(shape=[None,1],dtype=tf.float32, name='y-input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0R7Kaz8hOia",
        "colab_type": "code",
        "outputId": "28b82c9c-75b3-4b6a-9659-7c3b5b116b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'x-input:0' shape=(?, 13) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mJSeEKNAVzp",
        "colab_type": "code",
        "outputId": "ff8f0e3a-2d56-451f-ba7d-c92ce445983a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'y-input:0' shape=(?, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-CbymSMhOie",
        "colab_type": "text"
      },
      "source": [
        "Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wct4isvwhOif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_n = tf.nn.l2_normalize(x,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vT1EUENAsYH",
        "colab_type": "code",
        "outputId": "69cfa0e9-3b90-4d8e-a289-adc80f56c81e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'l2_normalize:0' shape=(?, 13) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YzUvCBRhOih",
        "colab_type": "text"
      },
      "source": [
        "Define Weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjRb2RmbhOii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.Variable(tf.zeros(shape=[13,1]), name=\"Weights\")\n",
        "b = tf.Variable(tf.zeros(shape=[1]),name=\"Bias\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GSTa6UHBy9L",
        "colab_type": "code",
        "outputId": "7b970c32-1372-4ce8-872f-4e0f4c44c471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Weights:0' shape=(13, 1) dtype=float32_ref>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw3SixYshOik",
        "colab_type": "text"
      },
      "source": [
        "Prediction - make sure to use normalized input features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MfPRdmtCuaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Matrix, Metrices, Tensors "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_5if0sLhOil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predition \n",
        "y = tf.add(tf.matmul(x_n,W),b,name='output')\n",
        "# y = w1x1 + w2x2 + w3x3 + ......... + w13x13"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRVY9ioahOin",
        "colab_type": "text"
      },
      "source": [
        "Loss (Cost) Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI43LP4CpFYx",
        "colab_type": "code",
        "outputId": "766c4f0b-85dd-407e-c315-3c9ffbe45555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'output:0' shape=(?, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJnDPaWHhOio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.square(y-y_),name='Loss')\n",
        "\n",
        "# <Summation & mean (((P-A)^2 ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG4FliPzhOiq",
        "colab_type": "text"
      },
      "source": [
        "GradientDescent Optimizer to minimize Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVSN_goRhOir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining the model through which the loss will be optimized \n",
        "train_op = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
        "\n",
        "# model =  sklearn.LinearRegression(c=01).fit(x,y)\n",
        "# model.predict(x)\n",
        "# model.score(model.predict(x),y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6zB64zRhOiv",
        "colab_type": "text"
      },
      "source": [
        "How do I define Learning Rate?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEUwOOgVhOiw",
        "colab_type": "text"
      },
      "source": [
        "# Executing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgiRpiQuhOix",
        "colab_type": "code",
        "outputId": "8c0393ab-5c27-4200-9c73-ecb7f3376a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Lets start graph Execution\n",
        "with tf.Session() as sess:\n",
        "    # variables need to be initialized before we can use them\n",
        "    # now is when the actual loading of variables will happen ---> lazy Loading \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    #how many times data need to be shown to model\n",
        "    training_epochs = 5000  \n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "        \n",
        "        #Calculate train_op and loss\n",
        "        # this is where you loss calculation and optimization will start happening \n",
        "        train_model, train_loss = sess.run([train_op,loss],feed_dict={x:features, y_:prices})\n",
        "        \n",
        "        if epoch % 100 == 0:\n",
        "            print ('Training loss at step: ', epoch, ' is ', train_loss)\n",
        "            print (sess.run([W,b]))\n",
        "            # put loss, W, b in Dictionary "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss at step:  0  is  592.1469\n",
            "[array([[7.2091222e-02],\n",
            "       [6.7363274e-01],\n",
            "       [3.8339737e-01],\n",
            "       [3.6395458e-03],\n",
            "       [2.2200951e-02],\n",
            "       [2.7616996e-01],\n",
            "       [2.6348557e+00],\n",
            "       [1.7608342e-01],\n",
            "       [3.0071834e-01],\n",
            "       [1.4883699e+01],\n",
            "       [7.5592577e-01],\n",
            "       [1.5748421e+01],\n",
            "       [4.2662460e-01]], dtype=float32), array([22.532808], dtype=float32)]\n",
            "Training loss at step:  100  is  62.029507\n",
            "[array([[-1.3966086e+00],\n",
            "       [ 9.4867220e+00],\n",
            "       [-1.7653874e+00],\n",
            "       [ 6.2991865e-02],\n",
            "       [ 4.1523003e-03],\n",
            "       [ 1.0707603e+00],\n",
            "       [-3.5260797e+00],\n",
            "       [ 2.1609995e-01],\n",
            "       [ 6.4603068e-02],\n",
            "       [-3.3688614e+00],\n",
            "       [-3.5347813e-01],\n",
            "       [ 1.8489540e+01],\n",
            "       [-5.0690641e+00]], dtype=float32), array([13.04741], dtype=float32)]\n",
            "Training loss at step:  200  is  60.355377\n",
            "[array([[-2.39483142e+00],\n",
            "       [ 1.57501020e+01],\n",
            "       [-3.15798903e+00],\n",
            "       [ 1.23543814e-01],\n",
            "       [ 1.09389634e-03],\n",
            "       [ 1.86102092e+00],\n",
            "       [-6.28572226e+00],\n",
            "       [ 6.22571781e-02],\n",
            "       [ 5.20396531e-01],\n",
            "       [-4.61778259e+00],\n",
            "       [-1.24450135e+00],\n",
            "       [ 1.69736080e+01],\n",
            "       [-9.86119652e+00]], dtype=float32), array([15.237856], dtype=float32)]\n",
            "Training loss at step:  300  is  59.182304\n",
            "[array([[-3.3826547e+00],\n",
            "       [ 2.0570000e+01],\n",
            "       [-4.3726649e+00],\n",
            "       [ 1.8523514e-01],\n",
            "       [ 7.3411583e-04],\n",
            "       [ 2.6290455e+00],\n",
            "       [-7.9230947e+00],\n",
            "       [-1.7721702e-01],\n",
            "       [ 9.7189093e-01],\n",
            "       [-5.8177638e+00],\n",
            "       [-2.1193440e+00],\n",
            "       [ 1.5618166e+01],\n",
            "       [-1.4467575e+01]], dtype=float32), array([17.19268], dtype=float32)]\n",
            "Training loss at step:  400  is  58.296078\n",
            "[array([[-4.3618960e+00],\n",
            "       [ 2.4298771e+01],\n",
            "       [-5.4541583e+00],\n",
            "       [ 2.4767096e-01],\n",
            "       [ 2.2138522e-03],\n",
            "       [ 3.3776488e+00],\n",
            "       [-8.7836733e+00],\n",
            "       [-4.8026457e-01],\n",
            "       [ 1.4199576e+00],\n",
            "       [-6.9609122e+00],\n",
            "       [-2.9848871e+00],\n",
            "       [ 1.4411775e+01],\n",
            "       [-1.8932316e+01]], dtype=float32), array([18.935848], dtype=float32)]\n",
            "Training loss at step:  500  is  57.5795\n",
            "[array([[-5.3333449e+00],\n",
            "       [ 2.7197317e+01],\n",
            "       [-6.4347386e+00],\n",
            "       [ 3.1057113e-01],\n",
            "       [ 4.9327593e-03],\n",
            "       [ 4.1091628e+00],\n",
            "       [-9.1120605e+00],\n",
            "       [-8.3074212e-01],\n",
            "       [ 1.8655866e+00],\n",
            "       [-8.0338345e+00],\n",
            "       [-3.8456662e+00],\n",
            "       [ 1.3336381e+01],\n",
            "       [-2.3286690e+01]], dtype=float32), array([20.494865], dtype=float32)]\n",
            "Training loss at step:  600  is  56.967342\n",
            "[array([[-6.2974353e+00],\n",
            "       [ 2.9460064e+01],\n",
            "       [-7.3379750e+00],\n",
            "       [ 3.7373897e-01],\n",
            "       [ 8.4703993e-03],\n",
            "       [ 4.8255577e+00],\n",
            "       [-9.0814505e+00],\n",
            "       [-1.2167262e+00],\n",
            "       [ 2.3093448e+00],\n",
            "       [-9.0303268e+00],\n",
            "       [-4.7046003e+00],\n",
            "       [ 1.2376107e+01],\n",
            "       [-2.7553062e+01]], dtype=float32), array([21.893291], dtype=float32)]\n",
            "Training loss at step:  700  is  56.422523\n",
            "[array([[-7.25436974e+00],\n",
            "       [ 3.12325764e+01],\n",
            "       [-8.18112087e+00],\n",
            "       [ 4.37037081e-01],\n",
            "       [ 1.25348205e-02],\n",
            "       [ 5.52851677e+00],\n",
            "       [-8.81382942e+00],\n",
            "       [-1.62938058e+00],\n",
            "       [ 2.75151157e+00],\n",
            "       [-9.94895363e+00],\n",
            "       [-5.56347799e+00],\n",
            "       [ 1.15170279e+01],\n",
            "       [-3.17473640e+01]], dtype=float32), array([23.151371], dtype=float32)]\n",
            "Training loss at step:  800  is  55.923412\n",
            "[array([[-8.2041960e+00],\n",
            "       [ 3.2624416e+01],\n",
            "       [-8.9768353e+00],\n",
            "       [ 5.0037092e-01],\n",
            "       [ 1.6925486e-02],\n",
            "       [ 6.2194715e+00],\n",
            "       [-8.3945551e+00],\n",
            "       [-2.0621305e+00],\n",
            "       [ 3.1921821e+00],\n",
            "       [-1.0791347e+01],\n",
            "       [-6.4233108e+00],\n",
            "       [ 1.0746931e+01],\n",
            "       [-3.5880943e+01]], dtype=float32), array([24.286545], dtype=float32)]\n",
            "Training loss at step:  900  is  55.45697\n",
            "[array([[-9.1468668e+00],\n",
            "       [ 3.3718472e+01],\n",
            "       [-9.7344284e+00],\n",
            "       [ 5.6367600e-01],\n",
            "       [ 2.1506656e-02],\n",
            "       [ 6.8996568e+00],\n",
            "       [-7.8828382e+00],\n",
            "       [-2.5100605e+00],\n",
            "       [ 3.6313307e+00],\n",
            "       [-1.1561041e+01],\n",
            "       [-7.2845802e+00],\n",
            "       [ 1.0055116e+01],\n",
            "       [-3.9961826e+01]], dtype=float32), array([25.313889], dtype=float32)]\n",
            "Training loss at step:  1000  is  55.015068\n",
            "[array([[-1.0082276e+01],\n",
            "       [ 3.4577877e+01],\n",
            "       [-1.0460783e+01],\n",
            "       [ 6.2690878e-01],\n",
            "       [ 2.6188284e-02],\n",
            "       [ 7.5701299e+00],\n",
            "       [-7.3193159e+00],\n",
            "       [-2.9694755e+00],\n",
            "       [ 4.0688605e+00],\n",
            "       [-1.2262669e+01],\n",
            "       [-8.1474161e+00],\n",
            "       [ 9.4321804e+00],\n",
            "       [-4.3995708e+01]], dtype=float32), array([26.246485], dtype=float32)]\n",
            "Training loss at step:  1100  is  54.592453\n",
            "[array([[-1.1010294e+01],\n",
            "       [ 3.5251057e+01],\n",
            "       [-1.1160982e+01],\n",
            "       [ 6.9004118e-01],\n",
            "       [ 3.0912332e-02],\n",
            "       [ 8.2318096e+00],\n",
            "       [-6.7314601e+00],\n",
            "       [-3.4375839e+00],\n",
            "       [ 4.5046334e+00],\n",
            "       [-1.2901384e+01],\n",
            "       [-9.0117226e+00],\n",
            "       [ 8.8699007e+00],\n",
            "       [-4.7986603e+01]], dtype=float32), array([27.095684], dtype=float32)]\n",
            "Training loss at step:  1200  is  54.185596\n",
            "[array([[-1.1930776e+01],\n",
            "       [ 3.5775360e+01],\n",
            "       [-1.1838835e+01],\n",
            "       [ 7.5305533e-01],\n",
            "       [ 3.5643011e-02],\n",
            "       [ 8.8854923e+00],\n",
            "       [-6.1374707e+00],\n",
            "       [-3.9122663e+00],\n",
            "       [ 4.9384942e+00],\n",
            "       [-1.3482511e+01],\n",
            "       [-9.8772564e+00],\n",
            "       [ 8.3610611e+00],\n",
            "       [-5.1937325e+01]], dtype=float32), array([27.871368], dtype=float32)]\n",
            "Training loss at step:  1300  is  53.792038\n",
            "[array([[-1.2843580e+01],\n",
            "       [ 3.6179871e+01],\n",
            "       [-1.2497183e+01],\n",
            "       [ 8.1594080e-01],\n",
            "       [ 4.0359844e-02],\n",
            "       [ 9.5318680e+00],\n",
            "       [-5.5490646e+00],\n",
            "       [-4.3918967e+00],\n",
            "       [ 5.3702836e+00],\n",
            "       [-1.4011292e+01],\n",
            "       [-1.0743696e+01],\n",
            "       [ 7.8993378e+00],\n",
            "       [-5.5849876e+01]], dtype=float32), array([28.582151], dtype=float32)]\n",
            "Training loss at step:  1400  is  53.41002\n",
            "[array([[-1.3748571e+01],\n",
            "       [ 3.6487370e+01],\n",
            "       [-1.3138189e+01],\n",
            "       [ 8.7869197e-01],\n",
            "       [ 4.5052644e-02],\n",
            "       [ 1.0171544e+01],\n",
            "       [-4.9734545e+00],\n",
            "       [-4.8752165e+00],\n",
            "       [ 5.7998505e+00],\n",
            "       [-1.4492755e+01],\n",
            "       [-1.1610681e+01],\n",
            "       [ 7.4791870e+00],\n",
            "       [-5.9725666e+01]], dtype=float32), array([29.235563], dtype=float32)]\n",
            "Training loss at step:  1500  is  53.03823\n",
            "[array([[-1.4645630e+01],\n",
            "       [ 3.6715862e+01],\n",
            "       [-1.3763495e+01],\n",
            "       [ 9.4130659e-01],\n",
            "       [ 4.9718168e-02],\n",
            "       [ 1.0805041e+01],\n",
            "       [-4.4147611e+00],\n",
            "       [-5.3612518e+00],\n",
            "       [ 6.2270513e+00],\n",
            "       [-1.4931613e+01],\n",
            "       [-1.2477849e+01],\n",
            "       [ 7.0957460e+00],\n",
            "       [-6.3565678e+01]], dtype=float32), array([29.838177], dtype=float32)]\n",
            "Training loss at step:  1600  is  52.67571\n",
            "[array([[-1.5534647e+01],\n",
            "       [ 3.6879704e+01],\n",
            "       [-1.4374359e+01],\n",
            "       [ 1.0037847e+00],\n",
            "       [ 5.4357558e-02],\n",
            "       [ 1.1432824e+01],\n",
            "       [-3.8750181e+00],\n",
            "       [-5.8492393e+00],\n",
            "       [ 6.6517520e+00],\n",
            "       [-1.5332220e+01],\n",
            "       [-1.3344795e+01],\n",
            "       [ 6.7447505e+00],\n",
            "       [-6.7370628e+01]], dtype=float32), array([30.395758], dtype=float32)]\n",
            "Training loss at step:  1700  is  52.321686\n",
            "[array([[-1.6415529e+01],\n",
            "       [ 3.6990414e+01],\n",
            "       [-1.4971777e+01],\n",
            "       [ 1.0661273e+00],\n",
            "       [ 5.8974747e-02],\n",
            "       [ 1.2055295e+01],\n",
            "       [-3.3548727e+00],\n",
            "       [-6.3385735e+00],\n",
            "       [ 7.0738425e+00],\n",
            "       [-1.5698566e+01],\n",
            "       [-1.4211180e+01],\n",
            "       [ 6.4224558e+00],\n",
            "       [-7.1141029e+01]], dtype=float32), array([30.913345], dtype=float32)]\n",
            "Training loss at step:  1800  is  51.97559\n",
            "[array([[-1.7288212e+01],\n",
            "       [ 3.7057335e+01],\n",
            "       [-1.5556526e+01],\n",
            "       [ 1.1283369e+00],\n",
            "       [ 6.3575178e-02],\n",
            "       [ 1.2672809e+01],\n",
            "       [-2.8540831e+00],\n",
            "       [-6.8287702e+00],\n",
            "       [ 7.4932227e+00],\n",
            "       [-1.6034277e+01],\n",
            "       [-1.5076664e+01],\n",
            "       [ 6.1255741e+00],\n",
            "       [-7.4877258e+01]], dtype=float32), array([31.395388], dtype=float32)]\n",
            "Training loss at step:  1900  is  51.636917\n",
            "[array([[-1.8152634e+01],\n",
            "       [ 3.7087944e+01],\n",
            "       [-1.6129234e+01],\n",
            "       [ 1.1904163e+00],\n",
            "       [ 6.8165131e-02],\n",
            "       [ 1.3285687e+01],\n",
            "       [-2.3718541e+00],\n",
            "       [-7.3194418e+00],\n",
            "       [ 7.9098082e+00],\n",
            "       [-1.6342617e+01],\n",
            "       [-1.5940936e+01],\n",
            "       [ 5.8512311e+00],\n",
            "       [-7.8579651e+01]], dtype=float32), array([31.845772], dtype=float32)]\n",
            "Training loss at step:  2000  is  51.305294\n",
            "[array([[-1.9008745e+01],\n",
            "       [ 3.7088497e+01],\n",
            "       [-1.6690409e+01],\n",
            "       [ 1.2523683e+00],\n",
            "       [ 7.2751038e-02],\n",
            "       [ 1.3894205e+01],\n",
            "       [-1.9070846e+00],\n",
            "       [-7.8102765e+00],\n",
            "       [ 8.3235264e+00],\n",
            "       [-1.6626513e+01],\n",
            "       [-1.6803719e+01],\n",
            "       [ 5.5968933e+00],\n",
            "       [-8.2248459e+01]], dtype=float32), array([32.267914], dtype=float32)]\n",
            "Training loss at step:  2100  is  50.980408\n",
            "[array([[-1.9856522e+01],\n",
            "       [ 3.7064114e+01],\n",
            "       [-1.7240479e+01],\n",
            "       [ 1.3141958e+00],\n",
            "       [ 7.7339336e-02],\n",
            "       [ 1.4498606e+01],\n",
            "       [-1.4585192e+00],\n",
            "       [-8.3010120e+00],\n",
            "       [ 8.7343216e+00],\n",
            "       [-1.6888597e+01],\n",
            "       [-1.7664749e+01],\n",
            "       [ 5.3603292e+00],\n",
            "       [-8.5883888e+01]], dtype=float32), array([32.66483], dtype=float32)]\n",
            "Training loss at step:  2200  is  50.66198\n",
            "[array([[-2.0695942e+01],\n",
            "       [ 3.7019035e+01],\n",
            "       [-1.7779804e+01],\n",
            "       [ 1.3759013e+00],\n",
            "       [ 8.1936128e-02],\n",
            "       [ 1.5099107e+01],\n",
            "       [-1.0248486e+00],\n",
            "       [-8.7914305e+00],\n",
            "       [ 9.1421490e+00],\n",
            "       [-1.7131207e+01],\n",
            "       [-1.8523792e+01],\n",
            "       [ 5.1395864e+00],\n",
            "       [-8.9486153e+01]], dtype=float32), array([33.03918], dtype=float32)]\n",
            "Training loss at step:  2300  is  50.34978\n",
            "[array([[-2.1527002e+01],\n",
            "       [ 3.6956814e+01],\n",
            "       [-1.8308683e+01],\n",
            "       [ 1.4374882e+00],\n",
            "       [ 8.6547069e-02],\n",
            "       [ 1.5695903e+01],\n",
            "       [-6.0478252e-01],\n",
            "       [-9.2813673e+00],\n",
            "       [ 9.5469685e+00],\n",
            "       [-1.7356426e+01],\n",
            "       [-1.9380650e+01],\n",
            "       [ 4.9329467e+00],\n",
            "       [-9.3055435e+01]], dtype=float32), array([33.393295], dtype=float32)]\n",
            "Training loss at step:  2400  is  50.04361\n",
            "[array([[-2.2349707e+01],\n",
            "       [ 3.6880386e+01],\n",
            "       [-1.8827396e+01],\n",
            "       [ 1.4989587e+00],\n",
            "       [ 9.1177300e-02],\n",
            "       [ 1.6289169e+01],\n",
            "       [-1.9709836e-01],\n",
            "       [-9.7706709e+00],\n",
            "       [ 9.9487553e+00],\n",
            "       [-1.7566135e+01],\n",
            "       [-2.0235130e+01],\n",
            "       [ 4.7388768e+00],\n",
            "       [-9.6591934e+01]], dtype=float32), array([33.729267], dtype=float32)]\n",
            "Training loss at step:  2500  is  49.743286\n",
            "[array([[-2.3164070e+01],\n",
            "       [ 3.6792225e+01],\n",
            "       [-1.9336180e+01],\n",
            "       [ 1.5603153e+00],\n",
            "       [ 9.5831424e-02],\n",
            "       [ 1.6879055e+01],\n",
            "       [ 1.9934638e-01],\n",
            "       [-1.0259226e+01],\n",
            "       [ 1.0347491e+01],\n",
            "       [-1.7761974e+01],\n",
            "       [-2.1087074e+01],\n",
            "       [ 4.5560541e+00],\n",
            "       [-1.0009590e+02]], dtype=float32), array([34.048916], dtype=float32)]\n",
            "Training loss at step:  2600  is  49.448643\n",
            "[array([[-2.39701118e+01],\n",
            "       [ 3.66944313e+01],\n",
            "       [-1.98352489e+01],\n",
            "       [ 1.62155998e+00],\n",
            "       [ 1.00513615e-01],\n",
            "       [ 1.74656944e+01],\n",
            "       [ 5.85599065e-01],\n",
            "       [-1.07469187e+01],\n",
            "       [ 1.07431641e+01],\n",
            "       [-1.79453945e+01],\n",
            "       [-2.19363384e+01],\n",
            "       [ 4.38330460e+00],\n",
            "       [-1.03567482e+02]], dtype=float32), array([34.353848], dtype=float32)]\n",
            "Training loss at step:  2700  is  49.159554\n",
            "[array([[-2.47678604e+01],\n",
            "       [ 3.65887527e+01],\n",
            "       [-2.03247929e+01],\n",
            "       [ 1.68269539e+00],\n",
            "       [ 1.05227515e-01],\n",
            "       [ 1.80492210e+01],\n",
            "       [ 9.62602437e-01],\n",
            "       [-1.12336683e+01],\n",
            "       [ 1.11357689e+01],\n",
            "       [-1.81177044e+01],\n",
            "       [-2.27827969e+01],\n",
            "       [ 4.21958733e+00],\n",
            "       [-1.07006927e+02]], dtype=float32), array([34.645493], dtype=float32)]\n",
            "Training loss at step:  2800  is  48.87587\n",
            "[array([[-2.55573521e+01],\n",
            "       [ 3.64766960e+01],\n",
            "       [-2.08049965e+01],\n",
            "       [ 1.74372280e+00],\n",
            "       [ 1.09976254e-01],\n",
            "       [ 1.86297417e+01],\n",
            "       [ 1.33120167e+00],\n",
            "       [-1.17194033e+01],\n",
            "       [ 1.15253067e+01],\n",
            "       [-1.82800655e+01],\n",
            "       [-2.36263409e+01],\n",
            "       [ 4.06398487e+00],\n",
            "       [-1.10414429e+02]], dtype=float32), array([34.925137], dtype=float32)]\n",
            "Training loss at step:  2900  is  48.59746\n",
            "[array([[ -26.338621  ],\n",
            "       [  36.359524  ],\n",
            "       [ -21.27603   ],\n",
            "       [   1.804644  ],\n",
            "       [   0.11476261],\n",
            "       [  19.207355  ],\n",
            "       [   1.6921499 ],\n",
            "       [ -12.204057  ],\n",
            "       [  11.9117775 ],\n",
            "       [ -18.433483  ],\n",
            "       [ -24.466877  ],\n",
            "       [   3.9156947 ],\n",
            "       [-113.79023   ]], dtype=float32), array([35.19388], dtype=float32)]\n",
            "Training loss at step:  3000  is  48.32422\n",
            "[array([[ -27.111717  ],\n",
            "       [  36.238285  ],\n",
            "       [ -21.738054  ],\n",
            "       [   1.865461  ],\n",
            "       [   0.11958893],\n",
            "       [  19.782156  ],\n",
            "       [   2.046108  ],\n",
            "       [ -12.687575  ],\n",
            "       [  12.295192  ],\n",
            "       [ -18.57888   ],\n",
            "       [ -25.30431   ],\n",
            "       [   3.773997  ],\n",
            "       [-117.13456   ]], dtype=float32), array([35.45273], dtype=float32)]\n",
            "Training loss at step:  3100  is  48.056026\n",
            "[array([[ -27.876694  ],\n",
            "       [  36.113907  ],\n",
            "       [ -22.191221  ],\n",
            "       [   1.9261749 ],\n",
            "       [   0.12445733],\n",
            "       [  20.354221  ],\n",
            "       [   2.3936603 ],\n",
            "       [ -13.169922  ],\n",
            "       [  12.67556   ],\n",
            "       [ -18.717054  ],\n",
            "       [ -26.138582  ],\n",
            "       [   3.6382632 ],\n",
            "       [-120.44764   ]], dtype=float32), array([35.702576], dtype=float32)]\n",
            "Training loss at step:  3200  is  47.79278\n",
            "[array([[ -28.633596 ],\n",
            "       [  35.987125 ],\n",
            "       [ -22.635662 ],\n",
            "       [   1.9867872],\n",
            "       [   0.1293694],\n",
            "       [  20.92363  ],\n",
            "       [   2.7353153],\n",
            "       [ -13.651051 ],\n",
            "       [  13.0528965],\n",
            "       [ -18.848732 ],\n",
            "       [ -26.969631 ],\n",
            "       [   3.5079272],\n",
            "       [-123.72973  ]], dtype=float32), array([35.944218], dtype=float32)]\n",
            "Training loss at step:  3300  is  47.53437\n",
            "[array([[ -29.382483  ],\n",
            "       [  35.85862   ],\n",
            "       [ -23.07152   ],\n",
            "       [   2.047299  ],\n",
            "       [   0.13432656],\n",
            "       [  21.490454  ],\n",
            "       [   3.0715218 ],\n",
            "       [ -14.130933  ],\n",
            "       [  13.427221  ],\n",
            "       [ -18.974539  ],\n",
            "       [ -27.7974    ],\n",
            "       [   3.3825    ],\n",
            "       [-126.98107   ]], dtype=float32), array([36.178345], dtype=float32)]\n",
            "Training loss at step:  3400  is  47.280704\n",
            "[array([[ -30.123413  ],\n",
            "       [  35.728912  ],\n",
            "       [ -23.498926  ],\n",
            "       [   2.1077113 ],\n",
            "       [   0.13933012],\n",
            "       [  22.05475   ],\n",
            "       [   3.4026635 ],\n",
            "       [ -14.60954   ],\n",
            "       [  13.798547  ],\n",
            "       [ -19.095041  ],\n",
            "       [ -28.621843  ],\n",
            "       [   3.2615426 ],\n",
            "       [-130.20192   ]], dtype=float32), array([36.40558], dtype=float32)]\n",
            "Training loss at step:  3500  is  47.031685\n",
            "[array([[ -30.85645   ],\n",
            "       [  35.598526  ],\n",
            "       [ -23.918007  ],\n",
            "       [   2.1680257 ],\n",
            "       [   0.14438094],\n",
            "       [  22.616585  ],\n",
            "       [   3.7290776 ],\n",
            "       [ -15.086846  ],\n",
            "       [  14.166898  ],\n",
            "       [ -19.210749  ],\n",
            "       [ -29.44292   ],\n",
            "       [   3.1446552 ],\n",
            "       [-133.3925    ]], dtype=float32), array([36.626495], dtype=float32)]\n",
            "Training loss at step:  3600  is  46.78722\n",
            "[array([[ -31.581652  ],\n",
            "       [  35.467686  ],\n",
            "       [ -24.328886  ],\n",
            "       [   2.2282426 ],\n",
            "       [   0.14947978],\n",
            "       [  23.17601   ],\n",
            "       [   4.051054  ],\n",
            "       [ -15.5628395 ],\n",
            "       [  14.532291  ],\n",
            "       [ -19.322107  ],\n",
            "       [ -30.260609  ],\n",
            "       [   3.0315027 ],\n",
            "       [-136.55309   ]], dtype=float32), array([36.841587], dtype=float32)]\n",
            "Training loss at step:  3700  is  46.547215\n",
            "[array([[ -32.299095 ],\n",
            "       [  35.336872 ],\n",
            "       [ -24.731678 ],\n",
            "       [   2.2883632],\n",
            "       [   0.1546273],\n",
            "       [  23.73307  ],\n",
            "       [   4.368841 ],\n",
            "       [ -16.037493 ],\n",
            "       [  14.894753 ],\n",
            "       [ -19.429514 ],\n",
            "       [ -31.074879 ],\n",
            "       [   2.9217675],\n",
            "       [-139.6839   ]], dtype=float32), array([37.051304], dtype=float32)]\n",
            "Training loss at step:  3800  is  46.311592\n",
            "[array([[ -33.00882  ],\n",
            "       [  35.206436 ],\n",
            "       [ -25.126505 ],\n",
            "       [   2.3483882],\n",
            "       [   0.1598238],\n",
            "       [  24.287807 ],\n",
            "       [   4.6826615],\n",
            "       [ -16.510803 ],\n",
            "       [  15.254308 ],\n",
            "       [ -19.533335 ],\n",
            "       [ -31.885712 ],\n",
            "       [   2.8151655],\n",
            "       [-142.78525  ]], dtype=float32), array([37.256058], dtype=float32)]\n",
            "Training loss at step:  3900  is  46.080254\n",
            "[array([[ -33.710915  ],\n",
            "       [  35.0765    ],\n",
            "       [ -25.513474  ],\n",
            "       [   2.4083188 ],\n",
            "       [   0.16506968],\n",
            "       [  24.840275  ],\n",
            "       [   4.9927077 ],\n",
            "       [ -16.98276   ],\n",
            "       [  15.610977  ],\n",
            "       [ -19.633875  ],\n",
            "       [ -32.69309   ],\n",
            "       [   2.7114618 ],\n",
            "       [-145.85736   ]], dtype=float32), array([37.456196], dtype=float32)]\n",
            "Training loss at step:  4000  is  45.853123\n",
            "[array([[ -34.405445  ],\n",
            "       [  34.947243  ],\n",
            "       [ -25.892696  ],\n",
            "       [   2.4681556 ],\n",
            "       [   0.17036514],\n",
            "       [  25.390503  ],\n",
            "       [   5.299139  ],\n",
            "       [ -17.45335   ],\n",
            "       [  15.964785  ],\n",
            "       [ -19.731419  ],\n",
            "       [ -33.49701   ],\n",
            "       [   2.6104388 ],\n",
            "       [-148.90053   ]], dtype=float32), array([37.652046], dtype=float32)]\n",
            "Training loss at step:  4100  is  45.63012\n",
            "[array([[ -35.092487 ],\n",
            "       [  34.818832 ],\n",
            "       [ -26.264282 ],\n",
            "       [   2.527899 ],\n",
            "       [   0.1757104],\n",
            "       [  25.938538 ],\n",
            "       [   5.6020956],\n",
            "       [ -17.92257  ],\n",
            "       [  16.315756 ],\n",
            "       [ -19.826233 ],\n",
            "       [ -34.297455 ],\n",
            "       [   2.5118933],\n",
            "       [-151.915    ]], dtype=float32), array([37.84391], dtype=float32)]\n",
            "Training loss at step:  4200  is  45.41115\n",
            "[array([[ -35.772095  ],\n",
            "       [  34.691418  ],\n",
            "       [ -26.628336  ],\n",
            "       [   2.5875504 ],\n",
            "       [   0.18110527],\n",
            "       [  26.484415  ],\n",
            "       [   5.901698  ],\n",
            "       [ -18.39041   ],\n",
            "       [  16.663912  ],\n",
            "       [ -19.918535  ],\n",
            "       [ -35.09443   ],\n",
            "       [   2.4156542 ],\n",
            "       [-154.90099   ]], dtype=float32), array([38.032036], dtype=float32)]\n",
            "Training loss at step:  4300  is  45.19615\n",
            "[array([[ -36.44435   ],\n",
            "       [  34.5651    ],\n",
            "       [ -26.984959  ],\n",
            "       [   2.6471102 ],\n",
            "       [   0.18654977],\n",
            "       [  27.028168  ],\n",
            "       [   6.1980505 ],\n",
            "       [ -18.85687   ],\n",
            "       [  17.009283  ],\n",
            "       [ -20.008545  ],\n",
            "       [ -35.887917  ],\n",
            "       [   2.321552  ],\n",
            "       [-157.8588    ]], dtype=float32), array([38.216675], dtype=float32)]\n",
            "Training loss at step:  4400  is  44.985046\n",
            "[array([[ -37.109314  ],\n",
            "       [  34.43996   ],\n",
            "       [ -27.334251  ],\n",
            "       [   2.7065792 ],\n",
            "       [   0.19204381],\n",
            "       [  27.569824  ],\n",
            "       [   6.4912457 ],\n",
            "       [ -19.321953  ],\n",
            "       [  17.351889  ],\n",
            "       [ -20.096436  ],\n",
            "       [ -36.677933  ],\n",
            "       [   2.2294543 ],\n",
            "       [-160.78864   ]], dtype=float32), array([38.398037], dtype=float32)]\n",
            "Training loss at step:  4500  is  44.777756\n",
            "[array([[ -37.76706  ],\n",
            "       [  34.316086 ],\n",
            "       [ -27.676315 ],\n",
            "       [   2.7659576],\n",
            "       [   0.1975872],\n",
            "       [  28.109417 ],\n",
            "       [   6.7813597],\n",
            "       [ -19.785648 ],\n",
            "       [  17.691765 ],\n",
            "       [ -20.182364 ],\n",
            "       [ -37.46447  ],\n",
            "       [   2.1392395],\n",
            "       [-163.69081  ]], dtype=float32), array([38.576305], dtype=float32)]\n",
            "Training loss at step:  4600  is  44.574207\n",
            "[array([[ -38.41766   ],\n",
            "       [  34.193497  ],\n",
            "       [ -28.011248  ],\n",
            "       [   2.8252459 ],\n",
            "       [   0.20317967],\n",
            "       [  28.646975  ],\n",
            "       [   7.068465  ],\n",
            "       [ -20.247953  ],\n",
            "       [  18.02892   ],\n",
            "       [ -20.266487  ],\n",
            "       [ -38.247543  ],\n",
            "       [   2.0507836 ],\n",
            "       [-166.56558   ]], dtype=float32), array([38.751667], dtype=float32)]\n",
            "Training loss at step:  4700  is  44.374332\n",
            "[array([[ -39.061184  ],\n",
            "       [  34.072273  ],\n",
            "       [ -28.339148  ],\n",
            "       [   2.8844457 ],\n",
            "       [   0.20882098],\n",
            "       [  29.182528  ],\n",
            "       [   7.352621  ],\n",
            "       [ -20.70888   ],\n",
            "       [  18.363388  ],\n",
            "       [ -20.348942  ],\n",
            "       [ -39.027153  ],\n",
            "       [   1.9639832 ],\n",
            "       [-169.41316   ]], dtype=float32), array([38.92429], dtype=float32)]\n",
            "Training loss at step:  4800  is  44.178055\n",
            "[array([[ -39.697704  ],\n",
            "       [  33.95241   ],\n",
            "       [ -28.660103  ],\n",
            "       [   2.9435577 ],\n",
            "       [   0.21451083],\n",
            "       [  29.716106  ],\n",
            "       [   7.6338816 ],\n",
            "       [ -21.168423  ],\n",
            "       [  18.695198  ],\n",
            "       [ -20.42985   ],\n",
            "       [ -39.803314  ],\n",
            "       [   1.8787459 ],\n",
            "       [-172.23383   ]], dtype=float32), array([39.09431], dtype=float32)]\n",
            "Training loss at step:  4900  is  43.98531\n",
            "[array([[ -40.327286  ],\n",
            "       [  33.833958  ],\n",
            "       [ -28.974209  ],\n",
            "       [   3.0025804 ],\n",
            "       [   0.22024883],\n",
            "       [  30.247726  ],\n",
            "       [   7.912289  ],\n",
            "       [ -21.626581  ],\n",
            "       [  19.024368  ],\n",
            "       [ -20.50931   ],\n",
            "       [ -40.576035  ],\n",
            "       [   1.7949854 ],\n",
            "       [-175.02782   ]], dtype=float32), array([39.26186], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQRmuKa-hOiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Summary is a TensorFlow op that creates protocol buffers containing summarized data\n",
        "\n",
        "\n",
        "training_loss = tf.summary.scalar('train_loss',loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTn2op1tJFYw",
        "colab_type": "code",
        "outputId": "3314dbda-4455-4bdb-d76e-c18f61a73a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'train_loss:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv3wI51vhOi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = \"/content/log/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEDsKuOXhOi_",
        "colab_type": "code",
        "outputId": "8d25c117-c15e-4913-b9d9-15c1c8278dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    training_epochs = 1000\n",
        "    #Logging and Saving graph\n",
        "    saver = tf.train.Saver()\n",
        "    writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())\n",
        "    #a python class that writes data to disk for Tensorboard\n",
        "    for epoch in range(training_epochs):\n",
        "        train_model, train_loss, loss_log = sess.run([train_op,loss,training_loss],feed_dict={x:features, y_:prices})\n",
        "        writer.add_summary(loss_log, epoch)\n",
        "        if epoch % 100 == 0:\n",
        "            print ('Training loss at step: ', epoch, 'is', train_loss)\n",
        "            print ('Log loss at step:', epoch, 'is', loss_log)\n",
        "    saver.save(sess,log_dir + '/' + 'boston.ckpt')\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss at step:  0 is 592.1469\n",
            "Log loss at step: 0 is b'\\n\\x11\\n\\ntrain_loss\\x15g\\t\\x14D'\n",
            "Training loss at step:  100 is 62.92511\n",
            "Log loss at step: 100 is b'\\n\\x11\\n\\ntrain_loss\\x15P\\xb3{B'\n",
            "Training loss at step:  200 is 61.639965\n",
            "Log loss at step: 200 is b'\\n\\x11\\n\\ntrain_loss\\x15S\\x8fvB'\n",
            "Training loss at step:  300 is 60.64175\n",
            "Log loss at step: 300 is b\"\\n\\x11\\n\\ntrain_loss\\x15'\\x91rB\"\n",
            "Training loss at step:  400 is 59.841866\n",
            "Log loss at step: 400 is b'\\n\\x11\\n\\ntrain_loss\\x15\\x12^oB'\n",
            "Training loss at step:  500 is 59.183144\n",
            "Log loss at step: 500 is b'\\n\\x11\\n\\ntrain_loss\\x15\\x8a\\xbblB'\n",
            "Training loss at step:  600 is 58.625896\n",
            "Log loss at step: 600 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xeb\\x80jB'\n",
            "Training loss at step:  700 is 58.142456\n",
            "Log loss at step: 700 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xe0\\x91hB'\n",
            "Training loss at step:  800 is 57.713425\n",
            "Log loss at step: 800 is b'\\n\\x11\\n\\ntrain_loss\\x15\\x8c\\xdafB'\n",
            "Training loss at step:  900 is 57.3251\n",
            "Log loss at step: 900 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xe7LeB'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh-aiOLThOjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}