{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Copy of Boston_Housing_Prices_Normalized.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhavadama/tensorflow/blob/master/Boston_Housing_Prices_Normalized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idLG9puGhOhc",
        "colab_type": "text"
      },
      "source": [
        "# Building a Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2k2oZJq6blt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK2CIQ_mhOhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9ptwssGhOhw",
        "colab_type": "text"
      },
      "source": [
        "Reset Default graph - Needed only for Jupyter notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmk6cNI-hOh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3-GxNaohOh_",
        "colab_type": "text"
      },
      "source": [
        "# Step 1 - Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k62nQK_mhOiB",
        "colab_type": "code",
        "outputId": "58d158a0-dda8-4198-fdb0-13c3f1624dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#Good people at tensorflow have provided the data \n",
        "from tensorflow.contrib.learn import datasets\n",
        "\n",
        "boston = datasets.load_dataset('boston')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-938abce5ef04>:3: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_boston (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use scikits.learn.datasets.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:129: load_csv_with_header (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.data instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRoEgOx5hOiE",
        "colab_type": "code",
        "outputId": "d8a576bf-7e7e-4aa3-cad1-7b6e3c33a7af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "boston"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(data=array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "        4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "        9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "        4.0300e+00],\n",
              "       ...,\n",
              "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        5.6400e+00],\n",
              "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "        6.4800e+00],\n",
              "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        7.8800e+00]]), target=array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT4loXnFhOiJ",
        "colab_type": "text"
      },
      "source": [
        "#Step 1a - Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou3nz2sshOiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input features\n",
        "features = np.array(boston.data)\n",
        "\n",
        "#Actual output\n",
        "prices = np.array(boston.target)\n",
        "prices = np.reshape(prices,[-1,1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw5cHoD9hOiQ",
        "colab_type": "code",
        "outputId": "1f40cc79-2df8-424a-ba18-246bd9c666d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "        4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "        9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "        4.0300e+00],\n",
              "       ...,\n",
              "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        5.6400e+00],\n",
              "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "        6.4800e+00],\n",
              "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        7.8800e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP5HCkSshOiT",
        "colab_type": "code",
        "outputId": "7e6bdeca-f79d-403f-a81f-3768a3f12803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "prices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[24. ],\n",
              "       [21.6],\n",
              "       [34.7],\n",
              "       [33.4],\n",
              "       [36.2],\n",
              "       [28.7],\n",
              "       [22.9],\n",
              "       [27.1],\n",
              "       [16.5],\n",
              "       [18.9],\n",
              "       [15. ],\n",
              "       [18.9],\n",
              "       [21.7],\n",
              "       [20.4],\n",
              "       [18.2],\n",
              "       [19.9],\n",
              "       [23.1],\n",
              "       [17.5],\n",
              "       [20.2],\n",
              "       [18.2],\n",
              "       [13.6],\n",
              "       [19.6],\n",
              "       [15.2],\n",
              "       [14.5],\n",
              "       [15.6],\n",
              "       [13.9],\n",
              "       [16.6],\n",
              "       [14.8],\n",
              "       [18.4],\n",
              "       [21. ],\n",
              "       [12.7],\n",
              "       [14.5],\n",
              "       [13.2],\n",
              "       [13.1],\n",
              "       [13.5],\n",
              "       [18.9],\n",
              "       [20. ],\n",
              "       [21. ],\n",
              "       [24.7],\n",
              "       [30.8],\n",
              "       [34.9],\n",
              "       [26.6],\n",
              "       [25.3],\n",
              "       [24.7],\n",
              "       [21.2],\n",
              "       [19.3],\n",
              "       [20. ],\n",
              "       [16.6],\n",
              "       [14.4],\n",
              "       [19.4],\n",
              "       [19.7],\n",
              "       [20.5],\n",
              "       [25. ],\n",
              "       [23.4],\n",
              "       [18.9],\n",
              "       [35.4],\n",
              "       [24.7],\n",
              "       [31.6],\n",
              "       [23.3],\n",
              "       [19.6],\n",
              "       [18.7],\n",
              "       [16. ],\n",
              "       [22.2],\n",
              "       [25. ],\n",
              "       [33. ],\n",
              "       [23.5],\n",
              "       [19.4],\n",
              "       [22. ],\n",
              "       [17.4],\n",
              "       [20.9],\n",
              "       [24.2],\n",
              "       [21.7],\n",
              "       [22.8],\n",
              "       [23.4],\n",
              "       [24.1],\n",
              "       [21.4],\n",
              "       [20. ],\n",
              "       [20.8],\n",
              "       [21.2],\n",
              "       [20.3],\n",
              "       [28. ],\n",
              "       [23.9],\n",
              "       [24.8],\n",
              "       [22.9],\n",
              "       [23.9],\n",
              "       [26.6],\n",
              "       [22.5],\n",
              "       [22.2],\n",
              "       [23.6],\n",
              "       [28.7],\n",
              "       [22.6],\n",
              "       [22. ],\n",
              "       [22.9],\n",
              "       [25. ],\n",
              "       [20.6],\n",
              "       [28.4],\n",
              "       [21.4],\n",
              "       [38.7],\n",
              "       [43.8],\n",
              "       [33.2],\n",
              "       [27.5],\n",
              "       [26.5],\n",
              "       [18.6],\n",
              "       [19.3],\n",
              "       [20.1],\n",
              "       [19.5],\n",
              "       [19.5],\n",
              "       [20.4],\n",
              "       [19.8],\n",
              "       [19.4],\n",
              "       [21.7],\n",
              "       [22.8],\n",
              "       [18.8],\n",
              "       [18.7],\n",
              "       [18.5],\n",
              "       [18.3],\n",
              "       [21.2],\n",
              "       [19.2],\n",
              "       [20.4],\n",
              "       [19.3],\n",
              "       [22. ],\n",
              "       [20.3],\n",
              "       [20.5],\n",
              "       [17.3],\n",
              "       [18.8],\n",
              "       [21.4],\n",
              "       [15.7],\n",
              "       [16.2],\n",
              "       [18. ],\n",
              "       [14.3],\n",
              "       [19.2],\n",
              "       [19.6],\n",
              "       [23. ],\n",
              "       [18.4],\n",
              "       [15.6],\n",
              "       [18.1],\n",
              "       [17.4],\n",
              "       [17.1],\n",
              "       [13.3],\n",
              "       [17.8],\n",
              "       [14. ],\n",
              "       [14.4],\n",
              "       [13.4],\n",
              "       [15.6],\n",
              "       [11.8],\n",
              "       [13.8],\n",
              "       [15.6],\n",
              "       [14.6],\n",
              "       [17.8],\n",
              "       [15.4],\n",
              "       [21.5],\n",
              "       [19.6],\n",
              "       [15.3],\n",
              "       [19.4],\n",
              "       [17. ],\n",
              "       [15.6],\n",
              "       [13.1],\n",
              "       [41.3],\n",
              "       [24.3],\n",
              "       [23.3],\n",
              "       [27. ],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [22.7],\n",
              "       [25. ],\n",
              "       [50. ],\n",
              "       [23.8],\n",
              "       [23.8],\n",
              "       [22.3],\n",
              "       [17.4],\n",
              "       [19.1],\n",
              "       [23.1],\n",
              "       [23.6],\n",
              "       [22.6],\n",
              "       [29.4],\n",
              "       [23.2],\n",
              "       [24.6],\n",
              "       [29.9],\n",
              "       [37.2],\n",
              "       [39.8],\n",
              "       [36.2],\n",
              "       [37.9],\n",
              "       [32.5],\n",
              "       [26.4],\n",
              "       [29.6],\n",
              "       [50. ],\n",
              "       [32. ],\n",
              "       [29.8],\n",
              "       [34.9],\n",
              "       [37. ],\n",
              "       [30.5],\n",
              "       [36.4],\n",
              "       [31.1],\n",
              "       [29.1],\n",
              "       [50. ],\n",
              "       [33.3],\n",
              "       [30.3],\n",
              "       [34.6],\n",
              "       [34.9],\n",
              "       [32.9],\n",
              "       [24.1],\n",
              "       [42.3],\n",
              "       [48.5],\n",
              "       [50. ],\n",
              "       [22.6],\n",
              "       [24.4],\n",
              "       [22.5],\n",
              "       [24.4],\n",
              "       [20. ],\n",
              "       [21.7],\n",
              "       [19.3],\n",
              "       [22.4],\n",
              "       [28.1],\n",
              "       [23.7],\n",
              "       [25. ],\n",
              "       [23.3],\n",
              "       [28.7],\n",
              "       [21.5],\n",
              "       [23. ],\n",
              "       [26.7],\n",
              "       [21.7],\n",
              "       [27.5],\n",
              "       [30.1],\n",
              "       [44.8],\n",
              "       [50. ],\n",
              "       [37.6],\n",
              "       [31.6],\n",
              "       [46.7],\n",
              "       [31.5],\n",
              "       [24.3],\n",
              "       [31.7],\n",
              "       [41.7],\n",
              "       [48.3],\n",
              "       [29. ],\n",
              "       [24. ],\n",
              "       [25.1],\n",
              "       [31.5],\n",
              "       [23.7],\n",
              "       [23.3],\n",
              "       [22. ],\n",
              "       [20.1],\n",
              "       [22.2],\n",
              "       [23.7],\n",
              "       [17.6],\n",
              "       [18.5],\n",
              "       [24.3],\n",
              "       [20.5],\n",
              "       [24.5],\n",
              "       [26.2],\n",
              "       [24.4],\n",
              "       [24.8],\n",
              "       [29.6],\n",
              "       [42.8],\n",
              "       [21.9],\n",
              "       [20.9],\n",
              "       [44. ],\n",
              "       [50. ],\n",
              "       [36. ],\n",
              "       [30.1],\n",
              "       [33.8],\n",
              "       [43.1],\n",
              "       [48.8],\n",
              "       [31. ],\n",
              "       [36.5],\n",
              "       [22.8],\n",
              "       [30.7],\n",
              "       [50. ],\n",
              "       [43.5],\n",
              "       [20.7],\n",
              "       [21.1],\n",
              "       [25.2],\n",
              "       [24.4],\n",
              "       [35.2],\n",
              "       [32.4],\n",
              "       [32. ],\n",
              "       [33.2],\n",
              "       [33.1],\n",
              "       [29.1],\n",
              "       [35.1],\n",
              "       [45.4],\n",
              "       [35.4],\n",
              "       [46. ],\n",
              "       [50. ],\n",
              "       [32.2],\n",
              "       [22. ],\n",
              "       [20.1],\n",
              "       [23.2],\n",
              "       [22.3],\n",
              "       [24.8],\n",
              "       [28.5],\n",
              "       [37.3],\n",
              "       [27.9],\n",
              "       [23.9],\n",
              "       [21.7],\n",
              "       [28.6],\n",
              "       [27.1],\n",
              "       [20.3],\n",
              "       [22.5],\n",
              "       [29. ],\n",
              "       [24.8],\n",
              "       [22. ],\n",
              "       [26.4],\n",
              "       [33.1],\n",
              "       [36.1],\n",
              "       [28.4],\n",
              "       [33.4],\n",
              "       [28.2],\n",
              "       [22.8],\n",
              "       [20.3],\n",
              "       [16.1],\n",
              "       [22.1],\n",
              "       [19.4],\n",
              "       [21.6],\n",
              "       [23.8],\n",
              "       [16.2],\n",
              "       [17.8],\n",
              "       [19.8],\n",
              "       [23.1],\n",
              "       [21. ],\n",
              "       [23.8],\n",
              "       [23.1],\n",
              "       [20.4],\n",
              "       [18.5],\n",
              "       [25. ],\n",
              "       [24.6],\n",
              "       [23. ],\n",
              "       [22.2],\n",
              "       [19.3],\n",
              "       [22.6],\n",
              "       [19.8],\n",
              "       [17.1],\n",
              "       [19.4],\n",
              "       [22.2],\n",
              "       [20.7],\n",
              "       [21.1],\n",
              "       [19.5],\n",
              "       [18.5],\n",
              "       [20.6],\n",
              "       [19. ],\n",
              "       [18.7],\n",
              "       [32.7],\n",
              "       [16.5],\n",
              "       [23.9],\n",
              "       [31.2],\n",
              "       [17.5],\n",
              "       [17.2],\n",
              "       [23.1],\n",
              "       [24.5],\n",
              "       [26.6],\n",
              "       [22.9],\n",
              "       [24.1],\n",
              "       [18.6],\n",
              "       [30.1],\n",
              "       [18.2],\n",
              "       [20.6],\n",
              "       [17.8],\n",
              "       [21.7],\n",
              "       [22.7],\n",
              "       [22.6],\n",
              "       [25. ],\n",
              "       [19.9],\n",
              "       [20.8],\n",
              "       [16.8],\n",
              "       [21.9],\n",
              "       [27.5],\n",
              "       [21.9],\n",
              "       [23.1],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [50. ],\n",
              "       [13.8],\n",
              "       [13.8],\n",
              "       [15. ],\n",
              "       [13.9],\n",
              "       [13.3],\n",
              "       [13.1],\n",
              "       [10.2],\n",
              "       [10.4],\n",
              "       [10.9],\n",
              "       [11.3],\n",
              "       [12.3],\n",
              "       [ 8.8],\n",
              "       [ 7.2],\n",
              "       [10.5],\n",
              "       [ 7.4],\n",
              "       [10.2],\n",
              "       [11.5],\n",
              "       [15.1],\n",
              "       [23.2],\n",
              "       [ 9.7],\n",
              "       [13.8],\n",
              "       [12.7],\n",
              "       [13.1],\n",
              "       [12.5],\n",
              "       [ 8.5],\n",
              "       [ 5. ],\n",
              "       [ 6.3],\n",
              "       [ 5.6],\n",
              "       [ 7.2],\n",
              "       [12.1],\n",
              "       [ 8.3],\n",
              "       [ 8.5],\n",
              "       [ 5. ],\n",
              "       [11.9],\n",
              "       [27.9],\n",
              "       [17.2],\n",
              "       [27.5],\n",
              "       [15. ],\n",
              "       [17.2],\n",
              "       [17.9],\n",
              "       [16.3],\n",
              "       [ 7. ],\n",
              "       [ 7.2],\n",
              "       [ 7.5],\n",
              "       [10.4],\n",
              "       [ 8.8],\n",
              "       [ 8.4],\n",
              "       [16.7],\n",
              "       [14.2],\n",
              "       [20.8],\n",
              "       [13.4],\n",
              "       [11.7],\n",
              "       [ 8.3],\n",
              "       [10.2],\n",
              "       [10.9],\n",
              "       [11. ],\n",
              "       [ 9.5],\n",
              "       [14.5],\n",
              "       [14.1],\n",
              "       [16.1],\n",
              "       [14.3],\n",
              "       [11.7],\n",
              "       [13.4],\n",
              "       [ 9.6],\n",
              "       [ 8.7],\n",
              "       [ 8.4],\n",
              "       [12.8],\n",
              "       [10.5],\n",
              "       [17.1],\n",
              "       [18.4],\n",
              "       [15.4],\n",
              "       [10.8],\n",
              "       [11.8],\n",
              "       [14.9],\n",
              "       [12.6],\n",
              "       [14.1],\n",
              "       [13. ],\n",
              "       [13.4],\n",
              "       [15.2],\n",
              "       [16.1],\n",
              "       [17.8],\n",
              "       [14.9],\n",
              "       [14.1],\n",
              "       [12.7],\n",
              "       [13.5],\n",
              "       [14.9],\n",
              "       [20. ],\n",
              "       [16.4],\n",
              "       [17.7],\n",
              "       [19.5],\n",
              "       [20.2],\n",
              "       [21.4],\n",
              "       [19.9],\n",
              "       [19. ],\n",
              "       [19.1],\n",
              "       [19.1],\n",
              "       [20.1],\n",
              "       [19.9],\n",
              "       [19.6],\n",
              "       [23.2],\n",
              "       [29.8],\n",
              "       [13.8],\n",
              "       [13.3],\n",
              "       [16.7],\n",
              "       [12. ],\n",
              "       [14.6],\n",
              "       [21.4],\n",
              "       [23. ],\n",
              "       [23.7],\n",
              "       [25. ],\n",
              "       [21.8],\n",
              "       [20.6],\n",
              "       [21.2],\n",
              "       [19.1],\n",
              "       [20.6],\n",
              "       [15.2],\n",
              "       [ 7. ],\n",
              "       [ 8.1],\n",
              "       [13.6],\n",
              "       [20.1],\n",
              "       [21.8],\n",
              "       [24.5],\n",
              "       [23.1],\n",
              "       [19.7],\n",
              "       [18.3],\n",
              "       [21.2],\n",
              "       [17.5],\n",
              "       [16.8],\n",
              "       [22.4],\n",
              "       [20.6],\n",
              "       [23.9],\n",
              "       [22. ],\n",
              "       [11.9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UIx_0tGhOiV",
        "colab_type": "text"
      },
      "source": [
        "How many examples do we have?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5x1LEjChOiW",
        "colab_type": "text"
      },
      "source": [
        "# Building the graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf4pxTu0hOiX",
        "colab_type": "text"
      },
      "source": [
        "Define input data placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvle5VWjhOiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input features\n",
        "x = tf.placeholder(shape=[None,13],dtype=tf.float32, name='x-input')\n",
        "\n",
        "#Actual Output\n",
        "y_ = tf.placeholder(shape=[None,1],dtype=tf.float32, name='y-input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0R7Kaz8hOia",
        "colab_type": "code",
        "outputId": "054c782d-9166-4ff8-eaae-baa60fc9c84e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'x-input:0' shape=(?, 13) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-CbymSMhOie",
        "colab_type": "text"
      },
      "source": [
        "Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wct4isvwhOif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_n = tf.nn.l2_normalize(x,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YzUvCBRhOih",
        "colab_type": "text"
      },
      "source": [
        "Define Weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjRb2RmbhOii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.Variable(tf.zeros(shape=[13,1]), name=\"Weights\")\n",
        "b = tf.Variable(tf.zeros(shape=[1]),name=\"Bias\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw3SixYshOik",
        "colab_type": "text"
      },
      "source": [
        "Prediction - make sure to use normalized input features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_5if0sLhOil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = tf.add(tf.matmul(x_n,W),b,name='output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRVY9ioahOin",
        "colab_type": "text"
      },
      "source": [
        "Loss (Cost) Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI43LP4CpFYx",
        "colab_type": "code",
        "outputId": "093a4f83-ee45-48bc-b4ed-a1cb7e38679b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'output_1:0' shape=(?, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJnDPaWHhOio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.square(y-y_),name='Loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG4FliPzhOiq",
        "colab_type": "text"
      },
      "source": [
        "GradientDescent Optimizer to minimize Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVSN_goRhOir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_op = tf.train.GradientDescentOptimizer(0.3).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6zB64zRhOiv",
        "colab_type": "text"
      },
      "source": [
        "How do I define Learning Rate?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEUwOOgVhOiw",
        "colab_type": "text"
      },
      "source": [
        "# Executing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgiRpiQuhOix",
        "colab_type": "code",
        "outputId": "cef36b66-1250-4b00-8605-a2a1aa5021cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Lets start graph Execution\n",
        "with tf.Session() as sess:\n",
        "    # variables need to be initialized before we can use them\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    #how many times data need to be shown to model\n",
        "    training_epochs = 1000  \n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "        \n",
        "        #Calculate train_op and loss\n",
        "        train_model, train_loss = sess.run([train_op,loss],feed_dict={x:features, y_:prices})\n",
        "        \n",
        "        if epoch % 100 == 0:\n",
        "            print ('Training loss at step: ', epoch, ' is ', train_loss)\n",
        "            print (sess.run([W,b]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss at step:  0  is  592.1469\n",
            "[array([[4.32547331e-02],\n",
            "       [4.04179662e-01],\n",
            "       [2.30038390e-01],\n",
            "       [2.18372745e-03],\n",
            "       [1.33205717e-02],\n",
            "       [1.65701985e-01],\n",
            "       [1.58091342e+00],\n",
            "       [1.05650045e-01],\n",
            "       [1.80430993e-01],\n",
            "       [8.93021965e+00],\n",
            "       [4.53555435e-01],\n",
            "       [9.44905186e+00],\n",
            "       [2.55974799e-01]], dtype=float32), array([13.519686], dtype=float32)]\n",
            "Training loss at step:  100  is  62.92511\n",
            "[array([[-9.8305494e-01],\n",
            "       [ 6.4261389e+00],\n",
            "       [-1.1337260e+00],\n",
            "       [ 3.8940318e-02],\n",
            "       [ 6.4115445e-03],\n",
            "       [ 7.4250525e-01],\n",
            "       [-1.9799651e+00],\n",
            "       [ 2.4457297e-01],\n",
            "       [-1.1225988e-01],\n",
            "       [-2.7040741e+00],\n",
            "       [ 9.9743241e-03],\n",
            "       [ 1.8946001e+01],\n",
            "       [-3.0634100e+00]], dtype=float32), array([12.0937], dtype=float32)]\n",
            "Training loss at step:  200  is  61.639965\n",
            "[array([[-1.5933676e+00],\n",
            "       [ 1.0844516e+01],\n",
            "       [-2.0546751e+00],\n",
            "       [ 7.4750647e-02],\n",
            "       [ 3.2926148e-03],\n",
            "       [ 1.2274864e+00],\n",
            "       [-4.1732044e+00],\n",
            "       [ 1.9375783e-01],\n",
            "       [ 1.5401484e-01],\n",
            "       [-3.6242559e+00],\n",
            "       [-5.2984375e-01],\n",
            "       [ 1.8181692e+01],\n",
            "       [-6.0252194e+00]], dtype=float32), array([13.490694], dtype=float32)]\n",
            "Training loss at step:  300  is  60.64175\n",
            "[array([[-2.1921167e+00],\n",
            "       [ 1.4597625e+01],\n",
            "       [-2.8894334e+00],\n",
            "       [ 1.1108783e-01],\n",
            "       [ 1.4748849e-03],\n",
            "       [ 1.7016355e+00],\n",
            "       [-5.8231306e+00],\n",
            "       [ 1.0112430e-01],\n",
            "       [ 4.2772210e-01],\n",
            "       [-4.3677993e+00],\n",
            "       [-1.0642622e+00],\n",
            "       [ 1.7270798e+01],\n",
            "       [-8.8997240e+00]], dtype=float32), array([14.8093605], dtype=float32)]\n",
            "Training loss at step:  400  is  59.841866\n",
            "[array([[-2.7870600e+00],\n",
            "       [ 1.7803217e+01],\n",
            "       [-3.6566889e+00],\n",
            "       [ 1.4786686e-01],\n",
            "       [ 6.9461181e-04],\n",
            "       [ 2.1675477e+00],\n",
            "       [-7.0417833e+00],\n",
            "       [-2.4083713e-02],\n",
            "       [ 6.9966418e-01],\n",
            "       [-5.0983176e+00],\n",
            "       [-1.5923666e+00],\n",
            "       [ 1.6418549e+01],\n",
            "       [-1.1703937e+01]], dtype=float32), array([16.038122], dtype=float32)]\n",
            "Training loss at step:  500  is  59.183144\n",
            "[array([[-3.3786683e+00],\n",
            "       [ 2.0546564e+01],\n",
            "       [-4.3673005e+00],\n",
            "       [ 1.8499115e-01],\n",
            "       [ 7.4236654e-04],\n",
            "       [ 2.6258996e+00],\n",
            "       [-7.9136553e+00],\n",
            "       [-1.7650007e-01],\n",
            "       [ 9.7007293e-01],\n",
            "       [-5.8127217e+00],\n",
            "       [-2.1158130e+00],\n",
            "       [ 1.5624173e+01],\n",
            "       [-1.4448614e+01]], dtype=float32), array([17.184034], dtype=float32)]\n",
            "Training loss at step:  600  is  58.625896\n",
            "[array([[-3.9671972e+00],\n",
            "       [ 2.2898642e+01],\n",
            "       [-5.0301690e+00],\n",
            "       [ 2.2238146e-01],\n",
            "       [ 1.4481135e-03],\n",
            "       [ 3.0772653e+00],\n",
            "       [-8.5075502e+00],\n",
            "       [-3.5170537e-01],\n",
            "       [ 1.2392578e+00],\n",
            "       [-6.5064983e+00],\n",
            "       [-2.6359501e+00],\n",
            "       [ 1.4883410e+01],\n",
            "       [-1.7142506e+01]], dtype=float32), array([18.253838], dtype=float32)]\n",
            "Training loss at step:  700  is  58.142456\n",
            "[array([[-4.5528321e+00],\n",
            "       [ 2.4918797e+01],\n",
            "       [-5.6526566e+00],\n",
            "       [ 2.5997347e-01],\n",
            "       [ 2.6740059e-03],\n",
            "       [ 3.5221670e+00],\n",
            "       [-8.8795509e+00],\n",
            "       [-5.4602194e-01],\n",
            "       [ 1.5074518e+00],\n",
            "       [-7.1764159e+00],\n",
            "       [-3.1538322e+00],\n",
            "       [ 1.4192272e+01],\n",
            "       [-1.9792765e+01]], dtype=float32), array([19.253637], dtype=float32)]\n",
            "Training loss at step:  800  is  57.713425\n",
            "[array([[-5.1357064e+00],\n",
            "       [ 2.6656754e+01],\n",
            "       [-6.2408609e+00],\n",
            "       [ 2.9771522e-01],\n",
            "       [ 4.3085413e-03],\n",
            "       [ 3.9610729e+00],\n",
            "       [-9.0752916e+00],\n",
            "       [-7.5638473e-01],\n",
            "       [ 1.7748257e+00],\n",
            "       [-7.8203254e+00],\n",
            "       [-3.6702733e+00],\n",
            "       [ 1.3547054e+01],\n",
            "       [-2.2405275e+01]], dtype=float32), array([20.189007], dtype=float32)]\n",
            "Training loss at step:  900  is  57.3251\n",
            "[array([[-5.7159128e+00],\n",
            "       [ 2.8154215e+01],\n",
            "       [-6.7998347e+00],\n",
            "       [ 3.3556461e-01],\n",
            "       [ 6.2617478e-03],\n",
            "       [ 4.3944097e+00],\n",
            "       [-9.1318464e+00],\n",
            "       [-9.8023748e-01],\n",
            "       [ 2.0414999e+00],\n",
            "       [-8.4369287e+00],\n",
            "       [-4.1858950e+00],\n",
            "       [ 1.2944330e+01],\n",
            "       [-2.4984810e+01]], dtype=float32), array([21.065027], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQRmuKa-hOiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Summary is a TensorFlow op that creates protocol buffers containing summarized data\n",
        "\n",
        "\n",
        "training_loss = tf.summary.scalar('train_loss',loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv3wI51vhOi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = \"/content/log/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEDsKuOXhOi_",
        "colab_type": "code",
        "outputId": "8d25c117-c15e-4913-b9d9-15c1c8278dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    training_epochs = 1000\n",
        "    #Logging and Saving graph\n",
        "    saver = tf.train.Saver()\n",
        "    writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())\n",
        "    #a python class that writes data to disk for Tensorboard\n",
        "    for epoch in range(training_epochs):\n",
        "        train_model, train_loss, loss_log = sess.run([train_op,loss,training_loss],feed_dict={x:features, y_:prices})\n",
        "        writer.add_summary(loss_log, epoch)\n",
        "        if epoch % 100 == 0:\n",
        "            print ('Training loss at step: ', epoch, 'is', train_loss)\n",
        "            print ('Log loss at step:', epoch, 'is', loss_log)\n",
        "    saver.save(sess,log_dir + '/' + 'boston.ckpt')\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss at step:  0 is 592.1469\n",
            "Log loss at step: 0 is b'\\n\\x11\\n\\ntrain_loss\\x15g\\t\\x14D'\n",
            "Training loss at step:  100 is 62.92511\n",
            "Log loss at step: 100 is b'\\n\\x11\\n\\ntrain_loss\\x15P\\xb3{B'\n",
            "Training loss at step:  200 is 61.639965\n",
            "Log loss at step: 200 is b'\\n\\x11\\n\\ntrain_loss\\x15S\\x8fvB'\n",
            "Training loss at step:  300 is 60.64175\n",
            "Log loss at step: 300 is b\"\\n\\x11\\n\\ntrain_loss\\x15'\\x91rB\"\n",
            "Training loss at step:  400 is 59.841866\n",
            "Log loss at step: 400 is b'\\n\\x11\\n\\ntrain_loss\\x15\\x12^oB'\n",
            "Training loss at step:  500 is 59.183144\n",
            "Log loss at step: 500 is b'\\n\\x11\\n\\ntrain_loss\\x15\\x8a\\xbblB'\n",
            "Training loss at step:  600 is 58.625896\n",
            "Log loss at step: 600 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xeb\\x80jB'\n",
            "Training loss at step:  700 is 58.142456\n",
            "Log loss at step: 700 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xe0\\x91hB'\n",
            "Training loss at step:  800 is 57.713425\n",
            "Log loss at step: 800 is b'\\n\\x11\\n\\ntrain_loss\\x15\\x8c\\xdafB'\n",
            "Training loss at step:  900 is 57.3251\n",
            "Log loss at step: 900 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xe7LeB'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh-aiOLThOjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}